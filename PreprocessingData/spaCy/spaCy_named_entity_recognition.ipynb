{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import common as c\n",
    "\n",
    "#The codes below are for specific example cleaning testing.\n",
    "raw_tag = '{BAGGU,groupbycolor,\"home goods\",Textiles}'\n",
    "raw_title = 'Reusable Cloth Set / Backyard Fruit'\n",
    "raw_product_type = 'textiles'\n",
    "#line 31 example\n",
    "raw_product_description = 'You may find yourself in a sticky situation. \\\n",
    "    You may need to secure that mushroom you came across in the woods. \\\n",
    "    You may need a tablecloth for a very small table. \\\n",
    "    You may have a runny nose or cold neck or be having a bad hair day and just want to cover it up. \\\n",
    "    You may ask yourself why you left home without a square of fabric. \\\n",
    "    You may have just found the solution — 20 square inches of pure possibility.\\\n",
    "    Details:Set of threeMeasures 20'' H x 20'' W100% Organic Cotton\\\n",
    "    About the Brand:Founded in 2007, BAGGU set out to create a reusable bag that was as functional as it was adorable. \\\n",
    "    Today their goal is to make every bag you need for your every day life. \\\n",
    "    They have stuck with their mission of creating useful products that are made with you and the planet in mind. \\\n",
    "    BAGGU is manufactured ethically and environmentally responsibly in China.'\n",
    "#pre-process the tag/title/product_type\n",
    "content_1 = c.clean_tags_text(raw_tag, raw_title, raw_product_type)\n",
    "#pre-process the production_description\n",
    "content_2 = c.clean_product_description(raw_product_description)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create TOPS type rule based matcher --> tops_matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_matcher = c.create_patterns_matcher()\n",
    "\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "tops_patterns = c.create_tops_patterns()\n",
    "\n",
    "tops_matcher = Matcher(nlp.vocab)\n",
    "#This rule_based matcher is only to detect \"TOPS\"\n",
    "tops_matcher.add(\"TOPS_TYPE\", tops_patterns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. First we are trainning model to detect all products belonging to 'TOPS'\n",
    "(TODO: overlap type in matcher eg. \"t-shirt\" -> 'shirt' and 't-shirt') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Solved) Overlap, duplicates, named entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('These camisole and T-shirt and are so good. I did have similar pattern jacket which is so fancy',\n",
       " {'entities': [(6, 14, 'TOPS'), (19, 26, 'TOPS'), (71, 77, 'TOPS')]})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_train_data(text):\n",
    "    doc = nlp(text)\n",
    "    #ignore for now \n",
    "    #detections = [(doc[start:end].start_char, doc[start:end].end_char, 'TOPS') for idx, start, end in type_matcher(doc) ]\n",
    "    \n",
    "    spans = [doc[start:end] for _, start, end in tops_matcher(doc)]\n",
    "    detections =  [(span.start_char, span.end_char, 'TOPS') for span in spacy.util.filter_spans(spans)] #remove duplicates or overlaps using spacy.util.filter_spans\n",
    "    \n",
    "    return (doc.text, {'entities': detections})\n",
    "\n",
    "#parse_train_data(\"I like my jacket\") testing, which should show the entities location\n",
    "parse_train_data(\"These camisole and T-shirt and are so good. I did have similar pattern jacket which is so fancy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Next step: We need to operate sample dataset to seperate the 'product_type_number == 2' to create classifier of 'TOPS' trainning model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from 150 train_data\n",
    "tops_df_1 = pd.read_csv('train_data/tops.csv', usecols=[\"title\", \"tags\", \"product_type\", \"body_html\"])\n",
    "#we will  build 180 train_data and 50 test_data 78% train 22% test for tops\n",
    "tops_df_2 = pd.read_csv('sample.csv', usecols=[\"title\", \"tags\", \"product_type\", \"body_html\"])\n",
    "tops_df = pd.concat([tops_df_1, tops_df_2], ignore_index=True)\n",
    "tops_df.to_csv('train_data/tops_total.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text_type = pd.read_csv('sample_v1.csv', usecols=[\"title\", \"tags\", \"product_type\", \"body_html\", \"product_type_number\"])\n",
    "\n",
    "tops_df = text_type.loc[text_type['product_type_number'] == '2'].reset_index()\n",
    "#pd.concat([pd.DataFrame([i], columns=['label']) for i in range(70)])\n",
    "\n",
    "tops_df.insert(len(tops_df.columns), 'label', 1, allow_duplicates=True)\n",
    "#print(\"columns number : \", len(tops_df.columns))\n",
    "\n",
    "#prdiction(mixed_all) is based on prediction1 + prdiction 2 (all words) a & b\n",
    "tops_df.insert(len(tops_df.columns), 'prediction(mixed_all)', 0, allow_duplicates=True)\n",
    "#prediction_1 is based on tags + title + product_type\n",
    "tops_df.insert(len(tops_df.columns), 'prediction_1(title+pt+tags)', 0, allow_duplicates=True)\n",
    "#prediction_2 is based on product_description(body_html)\n",
    "tops_df.insert(len(tops_df.columns), 'prediction_2(body_html)', 0, allow_duplicates=True)\n",
    "\n",
    "#fill all empty cells \n",
    "tops_df.fillna(\"Not mention\", inplace=True)\n",
    "tops_df.insert(len(tops_df.columns), 'based_on_title', 0, allow_duplicates=True)\n",
    "tops_df.insert(len(tops_df.columns), 'based_on_tags', 0, allow_duplicates=True)\n",
    "tops_df.insert(len(tops_df.columns), 'based_on_product_type', 0, allow_duplicates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tops_df.to_csv('sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop all rows with each row 'title', 'tags' and 'product_type' to create new column called 'title+tag'\n",
    "type_matcher = c.create_patterns_matcher()\n",
    "errorcount = 0\n",
    "for i in range(len(tops_df)):\n",
    "    content_2_raw = ''\n",
    "    content_1_raw = ''\n",
    "    content_raw = ''\n",
    "    titles_raw = ''\n",
    "    tags_raw = ''\n",
    "    ptype_raw = ''\n",
    "    try:\n",
    "        content_1_raw = c.clean_tags_text(tops_df.loc[i, 'tags'], tops_df.loc[i, 'title'], tops_df.loc[i, 'product_type'])\n",
    "        \n",
    "        titles_raw = c.clean_tags_text(None, tops_df.loc[i, 'title'], None)\n",
    "        \n",
    "        tags_raw = c.clean_tags_text(tops_df.loc[i, 'tags'], None, None)\n",
    "        \n",
    "        ptype_raw = c.clean_tags_text(None, None,  tops_df.loc[i, 'product_type'])\n",
    "        \n",
    "        content_2_raw = c.clean_product_description(tops_df.loc[i, 'body_html'])\n",
    "        \n",
    "        content_raw = content_1_raw + ', ' + content_2_raw\n",
    "        \n",
    "    except:\n",
    "        print(\"line type error \",i)\n",
    "    \n",
    "    content = nlp(content_raw)\n",
    "    content_1 = nlp(content_1_raw)\n",
    "    content_2 = nlp(content_2_raw)\n",
    "    titles = nlp(titles_raw)\n",
    "    tags = nlp(tags_raw)\n",
    "    ptype = nlp(ptype_raw)\n",
    "    \n",
    "    if len(type_matcher(titles)) > 0:\n",
    "        tops_df.loc[i, 'based_on_title'] = 1\n",
    "    \n",
    "    if len(type_matcher(tags)) > 0:\n",
    "        tops_df.loc[i, 'based_on_tags'] = 1\n",
    "        \n",
    "    if len(type_matcher(ptype)) > 0:\n",
    "        tops_df.loc[i, 'based_on_product_type'] = 1   \n",
    "    \n",
    "    if len(type_matcher(content_1)) > 0:\n",
    "        tops_df.loc[i, 'prediction_1(title+pt+tags)'] = 1\n",
    "        \n",
    "    if len(type_matcher(content_2)) > 0:\n",
    "        tops_df.loc[i, 'prediction_2(body_html)'] = 1\n",
    "    \n",
    "    if len(type_matcher(content)) > 0:\n",
    "        tops_df.loc[i, 'prediction(mixed_all)'] = 1\n",
    "    else:\n",
    "        errorcount += 1\n",
    "        print(errorcount, content_1_raw)\n",
    "        print(errorcount, content_2_raw)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. After every column using type_matcher, we update the 'prediction' column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tops_df.rename(columns={\"index\": \"index_in_original_sample\"}, inplace=True)\n",
    "tops_df.to_csv('TOPS_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_in_original_sample</th>\n",
       "      <th>title</th>\n",
       "      <th>product_type</th>\n",
       "      <th>tags</th>\n",
       "      <th>product_type_number</th>\n",
       "      <th>body_html</th>\n",
       "      <th>label</th>\n",
       "      <th>prediction(mixed_all)</th>\n",
       "      <th>prediction_1(title+pt+tags)</th>\n",
       "      <th>prediction_2(body_html)</th>\n",
       "      <th>based_on_title</th>\n",
       "      <th>based_on_tags</th>\n",
       "      <th>based_on_product_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index_in_original_sample, title, product_type, tags, product_type_number, body_html, label, prediction(mixed_all), prediction_1(title+pt+tags), prediction_2(body_html), based_on_title, based_on_tags, based_on_product_type]\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tops_df.loc[tops_df['prediction(mixed_all)'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_mixed_prediction_correctness :  1.0\n",
      "based_on_TagsTitleProductType_correctness 1.0\n",
      "based_on_title_correctness :  0.8048780487804879\n",
      "based_on_tags_correctness :  0.5487804878048781\n",
      "based_on_product_type_correctness :  0.6463414634146342\n",
      "based_on_body_html_correctness :  0.6097560975609756\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#print out the accuracy of each type matcher\n",
    "rows_count = tops_df[tops_df.columns[0]].count()\n",
    "all_mixed_prediction_correctness = (tops_df.loc[tops_df['prediction(mixed_all)'] == 1].shape[0]) / rows_count\n",
    "based_on_title_correctness = tops_df.loc[tops_df['based_on_title'] == 1].shape[0] / rows_count\n",
    "based_on_tags_correctness = tops_df.loc[tops_df['based_on_tags'] == 1].shape[0] / rows_count\n",
    "based_on_product_type_correctness = tops_df.loc[tops_df['based_on_product_type'] == 1].shape[0] / rows_count\n",
    "based_on_TagsTitleTags_correctness = tops_df.loc[tops_df['prediction_1(title+pt+tags)'] == 1].shape[0]/ rows_count\n",
    "based_on_body_html_correctness =tops_df.loc[tops_df['prediction_2(body_html)'] == 1].shape[0] / rows_count\n",
    "\n",
    "print(\"all_mixed_prediction_correctness : \", all_mixed_prediction_correctness)\n",
    "print(\"based_on_TagsTitleProductType_correctness\", based_on_TagsTitleTags_correctness)\n",
    "\n",
    "print(\"based_on_title_correctness : \", based_on_title_correctness)\n",
    "print(\"based_on_tags_correctness : \", based_on_tags_correctness)\n",
    "print(\"based_on_product_type_correctness : \", based_on_product_type_correctness)\n",
    "print(\"based_on_body_html_correctness : \", based_on_body_html_correctness)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Build TRIAN_DATA for 'tops'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first trainning set is containing title+productType together (concatenate three)\n",
    "\n",
    "title_tags_type_df = tops_df[['title', 'tags', 'product_type']]\n",
    "title_tags_type_df.insert(len(title_tags_type_df.columns), 'raw_combined_text', '')\n",
    "for i in range(len(title_tags_type_df)):\n",
    "    try:\n",
    "        raw_combined_text = c.clean_tags_text(title_tags_type_df.loc[i, 'tags'], title_tags_type_df.loc[i, 'title'], title_tags_type_df.loc[i, 'product_type'])\n",
    "        \n",
    "        title_tags_type_df.loc[i, 'raw_combined_text'] = raw_combined_text\n",
    "    except:\n",
    "        print(\"something wrong in line# : \", i)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     nu psychedelic, word is world sports bra, spor...\n",
       "1     free people tanks tops womens, scoop me up rac...\n",
       "2     mens national standard s/s t tops white, tribl...\n",
       "3     nu psychedelic, abstract waves black string bi...\n",
       "4     ready to ship, bees sweatshirt (clearance), re...\n",
       "                            ...                        \n",
       "77    basic carryover new regular sleeveless ss2021 ...\n",
       "78    20 bamboo pink sale ss2020 sunny top, peace to...\n",
       "79    _tab1_daydreamer-sizing _tab2_atb-daydreamer _...\n",
       "80    20 3/4 sleeve blouse carryover long sleeve ray...\n",
       "81    cotopaxi outerwear womens, cotopaxi women's te...\n",
       "Name: raw_combined_text, Length: 82, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_tags_type_df.loc[:,'raw_combined_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check our trian-dataframe title+tags+product_type\n",
    "TRAIN_DATA = [parse_train_data(d) for d in nlp.pipe(title_tags_type_df.loc[:,'raw_combined_text'])]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('animals nu psychedelic, acid gorilla hoodie, premium hoodie',\n",
       "  {'entities': [(37, 43, 'TOPS'), (53, 59, 'TOPS')]}),\n",
       " ('groupbycolor stateside tops, lounge l/s boat neck \" lightweight rib\" / black, tops',\n",
       "  {'entities': [(23, 27, 'TOPS'), (78, 82, 'TOPS')]}),\n",
       " ('_tab1_free-people-sizing _tab2_atb-free-people _tab3_care-free-people blouse clothing free-people tops, check on it wrap top, tops',\n",
       "  {'entities': [(70, 76, 'TOPS'),\n",
       "    (77, 85, 'TOPS'),\n",
       "    (98, 102, 'TOPS'),\n",
       "    (121, 124, 'TOPS'),\n",
       "    (126, 130, 'TOPS')]})]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_DATA [5:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAINNING LOOP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creat_blank_nlp(train_data):\n",
    "    nlp = spacy.blank(\"en\")\n",
    "    ner = nlp.create_pipe(\"ner\")\n",
    "    nlp.add_pipe(\"ner\", last=True)\n",
    "    ner = nlp.get_pipe(\"ner\")\n",
    "    for _, annotations in train_data:\n",
    "        for ent in annotations.get(\"entities\"):\n",
    "            try:\n",
    "                ner.add_label(ent[2])#'label' tops, ent[0], ent[1] are start_char and end_char\n",
    "            except:\n",
    "                print(ent[2])\n",
    "    return nlp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses at iteration 0 - 2022-05-26 13:11:25.442207 {'ner': 246.1788122681291}\n",
      "Losses at iteration 1 - 2022-05-26 13:11:26.446660 {'ner': 63.49363881912503}\n",
      "Losses at iteration 2 - 2022-05-26 13:11:27.358288 {'ner': 21.95635468829359}\n",
      "Losses at iteration 3 - 2022-05-26 13:11:28.264738 {'ner': 15.977096061168563}\n",
      "Losses at iteration 4 - 2022-05-26 13:11:29.216753 {'ner': 12.17571964220389}\n",
      "Losses at iteration 5 - 2022-05-26 13:11:30.137726 {'ner': 8.437774160626578}\n",
      "Losses at iteration 6 - 2022-05-26 13:11:31.057388 {'ner': 2.85108163488276}\n",
      "Losses at iteration 7 - 2022-05-26 13:11:32.008756 {'ner': 0.055176873039228566}\n",
      "Losses at iteration 8 - 2022-05-26 13:11:32.905828 {'ner': 2.719443597804182e-05}\n",
      "Losses at iteration 9 - 2022-05-26 13:11:33.774211 {'ner': 2.0649555189248358e-07}\n",
      "Losses at iteration 10 - 2022-05-26 13:11:34.655015 {'ner': 2.81540793139064e-07}\n",
      "Losses at iteration 11 - 2022-05-26 13:11:35.543226 {'ner': 9.963654621929166e-07}\n",
      "Losses at iteration 12 - 2022-05-26 13:11:36.416903 {'ner': 8.012720778090294e-08}\n",
      "Losses at iteration 13 - 2022-05-26 13:11:37.301166 {'ner': 1.1256224685126405e-06}\n",
      "Losses at iteration 14 - 2022-05-26 13:11:38.194009 {'ner': 3.1368098876102415e-08}\n",
      "Losses at iteration 15 - 2022-05-26 13:11:39.083224 {'ner': 6.622508979129693e-08}\n",
      "Losses at iteration 16 - 2022-05-26 13:11:39.998251 {'ner': 4.098714078582165e-08}\n",
      "Losses at iteration 17 - 2022-05-26 13:11:40.955937 {'ner': 2.8767357788780587e-07}\n",
      "Losses at iteration 18 - 2022-05-26 13:11:41.876537 {'ner': 2.182043549641851e-07}\n",
      "Losses at iteration 19 - 2022-05-26 13:11:43.042055 {'ner': 4.6046327131394677e-07}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import datetime as dt\n",
    "from spacy.training import Example\n",
    "nlp = creat_blank_nlp(TRAIN_DATA)\n",
    "optimizer = nlp.begin_training()\n",
    "for i in range(20):\n",
    "    random.shuffle(TRAIN_DATA)\n",
    "    losses = {}\n",
    "    for text, annotation in TRAIN_DATA:\n",
    "        try:\n",
    "            example = Example.from_dict(nlp.make_doc(text), annotation)\n",
    "            nlp.update([example], sgd=optimizer, losses=losses)\n",
    "        except:\n",
    "            print(\"Error happens on : \", text, annotation)\n",
    "    print(f\"Losses at iteration {i} - {dt.datetime.now()}\", losses)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">I wear a fancy \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    T-SHirt\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TOPS</span>\n",
       "</mark>\n",
       " and I got another button-down wonderful \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    crop\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TOPS</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    tee\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TOPS</span>\n",
       "</mark>\n",
       " . Long \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    shirt\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TOPS</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    coat\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TOPS</span>\n",
       "</mark>\n",
       " are necessary for keeping warm in winter. \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Sweater\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TOPS</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    blouse\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TOPS</span>\n",
       "</mark>\n",
       " are important for people living in the north. UA students have their own \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    hoodies\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TOPS</span>\n",
       "</mark>\n",
       ". The \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Tank Top\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TOPS</span>\n",
       "</mark>\n",
       " is new stylish top-clothes. What about \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    trying\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TOPS</span>\n",
       "</mark>\n",
       " our new camisole which is fantastic? </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from spacy import displacy\n",
    "\n",
    "#description is not accurate\n",
    "s = \"I wear a fancy T-SHirt and I got another button-down wonderful crop tee . \\\n",
    "    Long shirt and coat are necessary for keeping warm in winter. \\\n",
    "    Sweater and blouse are important for people living in the north. \\\n",
    "    UA students have their own hoodies. The Tank Top is new stylish top-clothes. \\\n",
    "    What about trying our new camisole which is fantastic? \"    \n",
    "doc2 = nlp(s)\n",
    "displacy.render(doc2, style='ent')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">There are certain pieces \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    that\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TOPS</span>\n",
       "</mark>\n",
       " will always bring a boho style aesthetic to mind, and this boxy \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    top\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TOPS</span>\n",
       "</mark>\n",
       " is one of them.     It's crafted from an open floral crochet with a scalloped hem and \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    short\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TOPS</span>\n",
       "</mark>\n",
       " sleeves.     We're showcasing the circle crochet trim along the round neckline with a turquoise necklace to really knock it out of the park. </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "s = \"There are certain pieces that will always bring a boho style aesthetic to mind, and this boxy top is one of them. \\\n",
    "    It's crafted from an open floral crochet with a scalloped hem and short sleeves. \\\n",
    "    We're showcasing the circle crochet trim along the round neckline with a turquoise necklace to really knock it out of the park. \"\n",
    "doc3 = nlp(s)\n",
    "displacy.render(doc3, style='ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">The Tempo \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Hoodie\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TOPS</span>\n",
       "</mark>\n",
       " is the UPF 50+ activewear you've been looking for!     It has \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    thumbholes\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TOPS</span>\n",
       "</mark>\n",
       ", a kangaroo pocket, and a hood for when the sun is too hot or you forgot your hat. Our Fitness \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Hoodie\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TOPS</span>\n",
       "</mark>\n",
       " is made out of our Active Athlon fabric with the added bonus of our Cooltect™ technology.     You can be active in this fitted \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Fitness\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TOPS</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Hoodie\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TOPS</span>\n",
       "</mark>\n",
       " without getting uncomfortably \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    hot\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TOPS</span>\n",
       "</mark>\n",
       ".     So go ahead and enjoy \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    sun-safe\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TOPS</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    biking\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TOPS</span>\n",
       "</mark>\n",
       ", walking, running and so much more!Highlights:UPF 50+Raglan long sleeves with thumbholesWelt kangaroo pocketHoodedActive Athlon™ fabric: Lightweight and breathable with     moisture wicking for quick dry performanceCooltect™ \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    technology\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TOPS</span>\n",
       "</mark>\n",
       " accelerates moisture wicking     to keep you \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    cooler\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TOPS</span>\n",
       "</mark>\n",
       " and more comfortable</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import common as c\n",
    "s4 = \"The Tempo Hoodie is the UPF 50+ activewear you've been looking for! \\\n",
    "    It has thumbholes, a kangaroo pocket, and a hood for when the sun is too hot or you forgot your hat. \\\n",
    "    Our Fitness Hoodie is made out of our Active Athlon fabric with the added bonus of our Cooltect™ technology. \\\n",
    "    You can be active in this fitted Fitness Hoodie without getting uncomfortably hot. \\\n",
    "    So go ahead and enjoy sun-safe biking, walking, running and so much more!Highlights:UPF 50+Raglan long sleeves with thumbholesWelt \\\n",
    "    kangaroo pocketHoodedActive Athlon™ fabric: Lightweight and breathable with moisture wicking for quick dry performanceCooltect™ technology \\\n",
    "    accelerates moisture wicking to keep you cooler and more comfortable\"\n",
    "doc4 = nlp(s4)\n",
    "displacy.render(doc4, style='ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ner', <spacy.pipeline.ner.EntityRecognizer at 0x2807716d0>)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline #We start with 'empty' pipeline, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Next step I will try to add more pipelines like tokenizer, tagger, parser, ner... \n",
    "label \n",
    "        ---> model ----> rules\n",
    "        \n",
    "data   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entity Ruler"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "08f33c96bfe48976e0772c3a4097c2fff4477ea59ec4556e2e8fa1251315c612"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
