{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Panda to concat, delete, insert, loc the data and I/O .csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas  as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. from tops_total.csv to operate some modifies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tops_df = pd.read_csv('tops_total_modified.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "#if we want to modify the row contain some errors with different names\n",
    "i = tops_df[(tops_df.product_type == \"cloak\")].index\n",
    "tops_df = tops_df.drop(i)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "j = tops_df[((tops_df.product_type == \"dress\") | (tops_df.product_type == \"dresses\") | (tops_df.product_type == \"dresses - formal\"))].index\n",
    "print(j)\n",
    "tops_df = tops_df.drop(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nOther operation for dataframes. \\nsince I put some files to different location, so the codes below just used once for creating tops_total.csv\\n#from all tops data we have to build the total dataset\\ntops_df_1 = pd.read_csv(\\'train_data/tops.csv\\', usecols=[\"title\", \"tags\", \"product_type\", \"body_html\"])  \\ntops_df_2 = pd.read_csv(\\'sample.csv\\', usecols=[\"title\", \"tags\", \"product_type\", \"body_html\"])\\ntops_df = pd.concat([tops_df_1, tops_df_2], ignore_index=True)\\ntops_df.to_csv(\\'train_data/tops_total.csv\\')\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Other operation for dataframes. \n",
    "since I put some files to different location, so the codes below just used once for creating tops_total.csv\n",
    "#from all tops data we have to build the total dataset\n",
    "tops_df_1 = pd.read_csv('train_data/tops.csv', usecols=[\"title\", \"tags\", \"product_type\", \"body_html\"])  \n",
    "tops_df_2 = pd.read_csv('sample.csv', usecols=[\"title\", \"tags\", \"product_type\", \"body_html\"])\n",
    "tops_df = pd.concat([tops_df_1, tops_df_2], ignore_index=True)\n",
    "tops_df.to_csv('train_data/tops_total.csv')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "k = tops_df[((tops_df.product_type == \"short\") | (tops_df.product_type == \"shorts\"))].index\n",
    "print(k)\n",
    "tops_df  = tops_df.drop(k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([213], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "l = tops_df[(tops_df.product_type == \"sweetlegs maternity\")].index\n",
    "print(l)\n",
    "tops_df = tops_df.drop(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean all unnessary rows and columns, we output the modified tops.csv\n",
    "tops_df = tops_df.loc[:, [\"title\",  \"product_type\", \"tags\", \"body_html\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tops_df.to_csv('tops.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create raw Train_data (.csv) and Test_data (.csv) from our total dataset (e.g 223 examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build 180 train_data and 44 test_data 80% train 20% test for tops 223 samples\n",
    "tops_df_train = tops_df.loc[0:180, [\"title\",  \"product_type\", \"tags\", \"body_html\"]].copy()\n",
    "tops_df_test = tops_df.loc[180:,  [\"title\",  \"product_type\", \"tags\", \"body_html\"]].copy()\n",
    "tops_df_train.to_csv('train_data/tops_train.csv', index= False)\n",
    "tops_df_test.to_csv('test_data/tops_test.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can concat our own columns at the end of the original columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "08f33c96bfe48976e0772c3a4097c2fff4477ea59ec4556e2e8fa1251315c612"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
