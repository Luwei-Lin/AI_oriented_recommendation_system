{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################\n",
    "# This script is for generating training dataset from \n",
    "# original .csv file by standardizing product_type and \n",
    "# labelling the first class label by algorithms.\n",
    "#\n",
    "# Please make sure the input file path and type is correct\n",
    "# Also, make sure product_to_all.json and main_to_num.json\n",
    "# in the same directory(or same path.) Since these two files\n",
    "# are the standardize information we use and the product label \n",
    "# map to number we predefined.\n",
    "# \n",
    "# Author: Luis Lin\n",
    "# Date: June 27, 2022\n",
    "#################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import spacy \n",
    "from difflib import SequenceMatcher\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "from string_grouper import match_strings, match_most_similar\n",
    "import numpy as np\n",
    "import text_cleaner as tc\n",
    "import re\n",
    "#the main_categories with all sub_categories dict\n",
    "products_to_all = {}\n",
    "#the main_categories relate to numbers dict\n",
    "main_categories_map_to_num = {}\n",
    "#all categories of product including the name of main_cat\n",
    "all_cat = set()\n",
    "#each specific item maps to the main_categories_number\n",
    "specific_products_map_to_num = {}\n",
    "\n",
    "'''\n",
    "Input: two separate strings\n",
    "Function:\n",
    "    We provide another statistic model (ML) from spacy.similarity to compare two strings similarity firstly.\n",
    "    if spacy similarities doesn't not exit like 0.0, then we compare two strings similarity by \"gestalt pattern matching\" \n",
    "    not_Statistic model(ML)  It is a character-based matcher. \n",
    "Output: Similarity [0, 1] between those two strings\n",
    "'''\n",
    "def similar(a: str, b: str) -> float:\n",
    "    nlp = spacy.load(\"en_core_web_md\")\n",
    "    doc1 = nlp(a)\n",
    "    doc2 = nlp(b)\n",
    "    statistical_method_score = doc1.similarity(doc2)\n",
    "    non_statistical_method_score = SequenceMatcher(None, a, b).ratio()\n",
    "    if statistical_method_score < 0.1:\n",
    "        return non_statistical_method_score\n",
    "    return statistical_method_score\n",
    "\n",
    "'''\n",
    "Input: string\n",
    "Function: remove any plural format and wired suffix, for example, dresses -> ['dress']\n",
    "Output: list \n",
    "'''\n",
    "def lemma_string(original_string:str) -> List:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(original_string.lower())\n",
    "    temp = []\n",
    "    for token in doc:\n",
    "        if token.text == '&' or token.text == 'and' or token.text == '/' or token.text == ',':\n",
    "            continue\n",
    "        if token.text == \"glasses\" or token.text == 'booty' or token.text == \"sunglasses\" or token.text == \"earrings\": #some of them should be represented in plural format\n",
    "            temp.append(token.text)\n",
    "        else:\n",
    "            temp.append(token.lemma_)\n",
    "    return temp\n",
    "'''\n",
    "input: original string\n",
    "function: remove pre_suffix of the original 'product_type' to match more accurate items\n",
    "output: modified string\n",
    "'''\n",
    "def modify_product_type(original:str):\n",
    "    if len(original) <= 1:\n",
    "        return original\n",
    "    removable_words = [\"clothing\", \"sale\", \"man\", \"men\", \"men's\", \"woman\", \"women\", \"women's\",  \"girl\", \"girls\", \"girl's\", \"lady\", \"ladies\", \"ladies'\", \"boy\", \"boys\", \"boy's\", \"graphic\", \"premium\", \"cozy\", \"comfort\", \"casual\", 'youth', 'adult']\n",
    "    original = original.replace(\"+\", \" \").replace(\"-\", \" \").replace(\"and\", \" \").replace(\"&\", \" \").replace(\"/\", \" \")\n",
    "    original = re.compile(r\"\\s+\").sub(\" \", original).strip()\n",
    "    ori_list = original.split(\" \")\n",
    "    \n",
    "    acc = ['acc', 'accessory', 'accessories']\n",
    "    shoes = ['footwear']\n",
    "    homeware = [\"home\", \"homeware\"]\n",
    "    main_cat = ''\n",
    "    sub_cat = []\n",
    "\n",
    "    res = []\n",
    "    \n",
    "    for e in ori_list:\n",
    "        e = e.strip().lower()\n",
    "        if e in removable_words:\n",
    "            continue\n",
    "        elif not res.__contains__(e):\n",
    "            res.append(e)\n",
    "            \n",
    "        if e in acc:\n",
    "            main_cat = \"accessories\"\n",
    "        elif e in shoes:\n",
    "            main_cat = \"shoes\"\n",
    "        elif e == \"tops\":\n",
    "            main_cat = \"tops\"\n",
    "        elif e == \"bottoms\":\n",
    "            main_cat = \"bottoms\"\n",
    "        elif e in homeware:\n",
    "            main_cat = \"homeware\"\n",
    "        elif e == \"beauty\":\n",
    "            main_cat = \"beauty\"\n",
    "        else:\n",
    "            sub_cat.append(e)\n",
    "    #if main_cat doesn't exist but sub_cat exists, we can try to map directly by specific_product_map\n",
    "    sub_cat = \" \".join(sub_cat)\n",
    "    \n",
    "    return \" \".join(res), main_cat, sub_cat\n",
    "\n",
    "\n",
    "'''\n",
    "Input: None\n",
    "Function: Read the .json file to initilize the dictionaries and sets\n",
    "Output: None\n",
    "'''\n",
    "def initiailize_containers() -> None:\n",
    "    with open(\"json_files/product_to_all.json\") as f1:\n",
    "        global products_to_all \n",
    "        products_to_all = json.load(f1)\n",
    "    with open(\"json_files/main_categories_to_num.json\") as f2: \n",
    "        global main_categories_map_to_num\n",
    "        main_categories_map_to_num = json.load(f2)\n",
    "    with open(\"json_files/specific_product_map_to_num.json\") as f3:\n",
    "        global specific_products_map_to_num\n",
    "        specific_products_map_to_num = json.load(f3)\n",
    "'''\n",
    "Input: dataframe\n",
    "Function: to calculate some statistics data after pre-processing.\n",
    "'''\n",
    "def summary_of_the_new_df(df:pd.DataFrame)->None:\n",
    "    unknown = 0\n",
    "    totalnum = df.shape[0]\n",
    "    shoes = 0\n",
    "    other_clothing = 0\n",
    "    tops = 0\n",
    "    bottoms = 0\n",
    "    beauty = 0\n",
    "    home = 0\n",
    "    acc = 0\n",
    "    other = 0\n",
    "    for row in range(df.shape[0]):\n",
    "        n = df.loc[row, \"label_1st\"]\n",
    "        if n == 0:\n",
    "            unknown += 1\n",
    "        elif n == 1:\n",
    "            shoes += 1\n",
    "        elif n == 2:\n",
    "            tops += 1\n",
    "        elif n == 3:\n",
    "            bottoms += 1\n",
    "        elif n == 4:\n",
    "            other_clothing += 1\n",
    "        elif n == 5:\n",
    "            beauty += 1\n",
    "        elif n == 6:\n",
    "            acc += 1\n",
    "        elif n == 7:\n",
    "            home += 1\n",
    "        elif n == 8:\n",
    "            other += 1\n",
    "        \n",
    "    print(\"unknown\", unknown, \"\\t\\tratio of all\", unknown/totalnum)\n",
    "    total = totalnum - unknown\n",
    "    print(\"\\nshoes\", shoes,\"\\t\\tratio\", \"{:10.2f}\".format(shoes/total))\n",
    "    print(\"tops\", tops, \"\\t\\tratio\", \"{:10.2f}\".format(tops/total))\n",
    "    print(\"bottoms\", bottoms, \"\\t\\tratio\", \"{:10.2f}\".format(bottoms/total))\n",
    "    print(\"other_clothing\", other_clothing,\"\\tratio\", \"{:10.2f}\".format(other_clothing/total))\n",
    "    print(\"beauty\", beauty, \"\\t\\tratio\", \"{:10.2f}\".format(beauty/total))\n",
    "    print(\"accessories\", acc, \"\\tratio\", \"{:10.2f}\".format(acc/total))\n",
    "    print(\"homeware\", home, \"\\t\\tratio\", \"{:10.2f}\".format(home/total))\n",
    "    print(\"other\", other, \"\\t\\tratio\", \"{:10.2f}\".format(other/total))\n",
    "#iniyilize all maps and sets.\n",
    "initiailize_containers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_file_path = \"/Users/luis/Downloads/products-June-28th.csv\"\n",
    "assert original_file_path != None\n",
    "columns = [\"id\", \"title\", \"tags\", \"images\", \"gender\",\"product_type\",  \"colors\", \"buckets\", \"url\", \"body_html\"]\n",
    "df = pd.DataFrame()\n",
    "try:\n",
    "    df = pd.read_csv(original_file_path, nrows = 500, usecols=columns).reset_index()\n",
    "except:\n",
    "    print(\"The path seems incorrect\")\n",
    "#insert new columns to this df which are useful and processed information \n",
    "\n",
    "df.insert(df.columns.get_loc(\"gender\"), \"product_type(modified)\", \"\", allow_duplicates=True)\n",
    "df.insert(df.columns.get_loc(\"gender\"), \"main_category\", \"\", allow_duplicates=True)\n",
    "df.insert(df.columns.get_loc(\"gender\"), \"sub_category\", \"\", allow_duplicates=True)\n",
    "df.insert(df.columns.get_loc(\"gender\"), \"match_most_similar_>80%_string\", \"\", allow_duplicates=True)\n",
    "df.insert(df.columns.get_loc(\"gender\"), \"match_most_similar_>60%_string\", \"\", allow_duplicates=True)\n",
    "df.insert(df.columns.get_loc(\"gender\"), \"label_1st\", 0, allow_duplicates=True)\n",
    "df.insert(df.columns.get_loc(\"gender\"), \"label_2nd\", 0, allow_duplicates=True)\n",
    "df.insert(df.columns.get_loc(\"gender\"), \"label_3rd\", 0, allow_duplicates=True)\n",
    "df.insert(df.columns.get_loc(\"buckets\"), \"buckets_num\", 0, allow_duplicates=True)\n",
    "df.insert(df.columns.get_loc(\"url\"), \"color_num\", 0, allow_duplicates=True)\n",
    "df = df[[\"index\",\"id\", \"title\", \"tags\", \"images\", \"gender\",\"product_type\", \"product_type(modified)\", \"main_category\", \"sub_category\", \"match_most_similar_>80%_string\", \"match_most_similar_>60%_string\", \"label_1st\", \"label_2nd\",\"label_3rd\", \"buckets_num\", \"buckets\", \"color_num\", \"colors\", \"url\", \"body_html\"]]\n",
    "df.insert(df.columns.get_loc(\"body_html\"), \"raw_text\", \"\", allow_duplicates=True)\n",
    "for i in range(df.shape[0]):\n",
    "    \n",
    "    ori_word = df.loc[i, 'product_type']\n",
    "    title = df.loc[i, 'title']\n",
    "    tags = df.loc[i, 'tags']\n",
    "    buckets = df.loc[i, 'buckets']\n",
    "    body_html = df.loc[i, 'body_html']\n",
    "    \n",
    "    if not isinstance(ori_word, str):\n",
    "        df.loc[i,['product_type']] = \"unknown\"\n",
    "        df.loc[i, ['product_type(modified)']] = \"unknown\"\n",
    "        continue\n",
    "    #get the modify_product_type (remove)\n",
    "    try:\n",
    "        product_type_new, main_cat, sub_cat= modify_product_type(ori_word)\n",
    "        df.loc[i, ['product_type(modified)']] = product_type_new\n",
    "        df.loc[i, [\"main_category\"]] = main_cat\n",
    "        df.loc[i, [\"sub_category\"]] = sub_cat\n",
    "    except:\n",
    "        print(i, ori_word)\n",
    "    \n",
    "    try:\n",
    "        df.loc[i, 'raw_text'] = tc.cleanHtml(body_html)\n",
    "    except:\n",
    "        print(\"Something wrong with clean html: \", i)\n",
    "del(df[\"body_html\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#build data series from all categories.\n",
    "pre_defiened_labels = pd.Series(list(all_cat), name=\"pre_defined_label\")\n",
    "#get 80% most_similar_mathes(dataframe) by using package string-matcher\n",
    "\n",
    "most_similar_matches = match_most_similar( pre_defiened_labels, df[\"product_type(modified)\"],\\\n",
    "    min_similarity = 0.80, ignore_index=False, replace_na=False)\n",
    "most_similar_matches = pd.concat([df['index'],df[\"product_type(modified)\"], most_similar_matches], axis=1)\n",
    "#get 60% most_similar_matches(dataframe) \n",
    "less_similar_matches = match_strings(pre_defiened_labels, df[\"product_type(modified)\"],\\\n",
    "    min_similarity = 0.65, ignore_index = False, replace_na = False)\n",
    "#fill up 80% most_similar_80% column\n",
    "empty_cells = 0\n",
    "for row in range(most_similar_matches.shape[0]):\n",
    "    index = most_similar_matches.loc[row, \"index\"]\n",
    "    most_similar_pre_defined_label = most_similar_matches.loc[row, 'most_similar_pre_defined_label']\n",
    "    most_similar_index = most_similar_matches.loc[row, ['most_similar_index']].item()\n",
    "    \n",
    "    if not np.isnan(most_similar_index):\n",
    "        df.loc[df['index'] == index, ['match_most_similar_>80%_string']] = most_similar_pre_defined_label\n",
    "    else:\n",
    "        empty_cells += 1\n",
    "#fill up 60% less_similar_60% column\n",
    "index_similarity_map = {}\n",
    "index_to_pre_map = {}\n",
    "for row in range(less_similar_matches.shape[0]):\n",
    "    current_index = less_similar_matches.loc[row, 'right_index']\n",
    "    label = less_similar_matches.loc[row, 'left_pre_defined_label']\n",
    "    similarity = less_similar_matches.loc[row, 'similarity']\n",
    "    \n",
    "    if index_similarity_map.get(current_index) == None:\n",
    "        index_similarity_map.update({current_index:similarity})\n",
    "        index_to_pre_map.update({current_index:label})\n",
    "    elif index_similarity_map.get(current_index) >= similarity:\n",
    "        index_similarity_map.update({current_index:similarity})\n",
    "        index_to_pre_map.update({current_index:label})\n",
    "    else: # similarity < then current, ignore\n",
    "        continue\n",
    "for key in index_to_pre_map.keys():\n",
    "    df.loc[df['index'] == key, ['match_most_similar_>60%_string']] = index_to_pre_map.get(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"look.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Algorithm 2: if both 60% and 80% don't exist, just ignore, \n",
    "#             if the 80% string doesn't exist, compare the 60% string with 80% string similarity by diff() and spacy(), \n",
    "#             let spacy.similarity to decide whether above 60% to fill the 80%. if spacy similarity does not exist, fill \n",
    "#             fill up 80% by similar() algorithm. \n",
    "double_check_pairs_pt_word60_dic = {}\n",
    "#see the accurancy \n",
    "\n",
    "def is_nan_string(string):\n",
    "    return string != string\n",
    "#w = df.loc[66, [\"match_most_similar_>80%_string\"]].item()\n",
    "#print(w)\n",
    "#is_nan_string(w)\n",
    "for row in range(df.shape[0]):\n",
    "    word_80 = df.loc[row, [\"match_most_similar_>80%_string\"]].item()\n",
    "    word_60 = df.loc[row, [\"match_most_similar_>60%_string\"]].item()\n",
    "    if is_nan_string(word_80 ) and is_nan_string(word_60):\n",
    "        continue\n",
    "    elif is_nan_string(word_80) and not is_nan_string(word_60):\n",
    "        pt_modified = df.loc[row, \"product_type(modified)\"]\n",
    "        pair = (pt_modified, word_60)\n",
    "        if pair not in double_check_pairs_pt_word60_dic.keys():\n",
    "            print(pair)\n",
    "            double_check_pairs_pt_word60_dic.update({pair: similar(word_60, pt_modified)})\n",
    "        #print(\"product_type(modified) \", pt_modified, \" words(60%): \", word_60, \" Similarity: \", similar(word_60, pt_modified))\n",
    "        if similar(word_60, pt_modified) > 0.5:\n",
    "            df.loc[row, \"match_most_similar_>80%_string\"] = word_60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty body_html:  1165  which is around:       0.04\n",
      "product_type 'extra' :  22117  which is around       0.80\n"
     ]
    }
   ],
   "source": [
    "#From previous we finished match similar products. We start to label the \"label_1st\" column\n",
    "empty_body_html = 0\n",
    "extra_product_type = 0\n",
    "for row in range(df.shape[0]):\n",
    "    key = df.loc[row, ['match_most_similar_>80%_string']].item()\n",
    "    if key != None and specific_products_map_to_num.get(key) != None:\n",
    "        df.loc[row, ['label_1st']] = specific_products_map_to_num.get(key)\n",
    "    else:\n",
    "        df.loc[row, ['label_1st']] = 0\n",
    "    #also we want to create raw-text from title tags and description import text-cleaner\n",
    "    try:\n",
    "        title = df.loc[row, \"title\"]\n",
    "        tags =  df.loc[row, \"tags\"]\n",
    "        body_html = df.loc[row, \"body_html\"]\n",
    "        buckets = df.loc[row, \"buckets\"]\n",
    "        if is_nan_string(body_html):\n",
    "            body_html = None\n",
    "            empty_body_html += 1\n",
    "        df.loc[row, \"raw_text\"] = raw_content(title, tags, body_html, buckets)\n",
    "        \n",
    "    except:\n",
    "        print(row, df.loc[row, \"title\"], df.loc[row, \"tags\"], df.loc[row,\"body_html\"])\n",
    "        \n",
    "    if df.loc[row, \"product_type\"].lower() == 'extra':\n",
    "        extra_product_type += 1\n",
    "print(\"Empty body_html: \", empty_body_html, \" which is around: {:10.2f}\".format(empty_body_html/df.shape[0]))\n",
    "print(\"product_type 'extra' : \", extra_product_type, \" which is around {:10.2f}\".format(extra_product_type/df.shape[0]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unknown 22561 \t\tratio of all 0.8109924871490708\n",
      "\n",
      "shoes 0 \t\tratio       0.00\n",
      "tops 2612 \t\tratio       0.50\n",
      "bottoms 889 \t\tratio       0.17\n",
      "other_clothing 7 \tratio       0.00\n",
      "beauty 94 \t\tratio       0.02\n",
      "accessories 1654 \tratio       0.31\n",
      "homeware 0 \t\tratio       0.00\n",
      "other 2 \t\tratio       0.00\n"
     ]
    }
   ],
   "source": [
    "summary_of_the_new_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(\"processed_products_June28.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27819"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for row in range(df.shape[0]):\n",
    "    if not df.loc[row, 'raw_text'].__contains__(\"FEATURE\"):\n",
    "        count += 1\n",
    "\n",
    "count"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "08f33c96bfe48976e0772c3a4097c2fff4477ea59ec4556e2e8fa1251315c612"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
