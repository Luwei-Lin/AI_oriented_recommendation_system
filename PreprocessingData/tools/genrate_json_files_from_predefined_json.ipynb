{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################\n",
    "# This script is for generating map.json from \n",
    "# original label_v2.json file by standardizing predefined product_type\n",
    "#\n",
    "# Please make sure the input file path and type is correct\n",
    "#\n",
    "# \n",
    "# Author: Luis Lin\n",
    "# Date: June 27, 2022\n",
    "#################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Plugin\n",
      "Init Graph Optimizer\n",
      "Init Kernel\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from typing import List\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"/Users/luis/Documents/GitHub/2022Summer/AI-Oriented-Recommendation-System/PreprocessingData/tools/json_files/labels_v2.json\")\n",
    "label = json.load(f)\n",
    "pt = label.get(\"product_type\")\n",
    "st = label.get(\"sub_product_type\")\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "'''\n",
    "input: list, e.g. ['t', '-', 'shirt'], ['high', '-', 'rise', 'shoe']\n",
    "function: deal with the list with '-' punct\n",
    "output: \"t-shirt\" \"high-rise shoe\" \"a-b-c color\" \n",
    "'''\n",
    "def check_and_concat_punct(temp:List[str]) -> str:\n",
    "    temp_string = \"\"\n",
    "    if temp.__contains__('-') and len(temp) == 3:\n",
    "        temp_string = ''.join(temp)\n",
    "    elif temp.__contains__('-') and len(temp) > 3:\n",
    "        \n",
    "        pos = temp.index('-')\n",
    "        #if there is wrong position of '-'\n",
    "        if pos < 1:\n",
    "            temp_string = ' '.join(temp)\n",
    "            return temp_string\n",
    "        \n",
    "        puct_string = temp[pos - 1] + temp[pos] + temp[pos + 1]\n",
    "        rest_string = ' '.join(temp[pos + 2:])\n",
    "        temp_string = puct_string + ' '+ rest_string\n",
    "    else:\n",
    "        temp_string = ' '.join(temp)\n",
    "    \n",
    "    return temp_string \n",
    "\n",
    "'''\n",
    "input: original string e.g. 'scandals', 'jackets/coats'\n",
    "funct: clean the string to the original words and put to list\n",
    "output: ['scandal'], ['jacket', 'coats'] \n",
    "'''\n",
    "def lemma_string(original_string:str) -> List:\n",
    "    doc = nlp(original_string.lower())\n",
    "    temp = []\n",
    "    for token in doc:\n",
    "        if token.text == '&' or token.text == 'and' or token.text == '/' or token.text == ',':\n",
    "            continue\n",
    "        if token.text == \"glasses\" or token.text == 'booty' or token.text == 'jackets' or token.text == \"cycling\"\\\n",
    "            or token.text == \"sunglasses\" or token.text == \"earrings\" or token.text == 'coats': #some of them should be represented in plural format\n",
    "            temp.append(token.text)\n",
    "        else:\n",
    "            temp.append(token.lemma_)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_cat_all_keys = [key for key in st[0].keys()]\n",
    "sub_cat_shoes_keys = sub_cat_all_keys[0:4]\n",
    "sub_cat_tops_keys= sub_cat_all_keys[4:7]\n",
    "sub_cat_other_clothing_keys = sub_cat_all_keys[7:8] + sub_cat_all_keys[13:14]\n",
    "sub_cat_bottoms_keys = sub_cat_all_keys[8:13]\n",
    "sub_cat_acc_keys = sub_cat_all_keys[14: 19]\n",
    "sub_cat_beauty_keys = sub_cat_all_keys[19: ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_main = {key for key in pt[0].keys()}\n",
    "#print(\"First: \\n\",  all_main)\n",
    "#set\n",
    "all_sub_main = set()\n",
    "#dict { 'shoes': {(all shoe types whatever it is the 2nd or 3rd class label)} }\n",
    "products_to_all = {}\n",
    "#dict { 'shoes': 1, ''}\n",
    "main_categories_map_to_num = {}\n",
    "#dict { 'heels': 1, 't-shirt': } specific item maps to the number\n",
    "specific_products_map_to_num = {}\n",
    "pt_index = 0\n",
    "for key in pt[0].keys():\n",
    "    product_name_2nd_list = pt[0].get(key)\n",
    "    pt_key = key\n",
    "    pt_value_set = set()\n",
    "    \n",
    "    for item_string in product_name_2nd_list:\n",
    "        \n",
    "        temp = lemma_string(item_string)\n",
    "        temp_string = check_and_concat_punct(temp)\n",
    "        \n",
    "        #update set\n",
    "        all_sub_main.add(temp_string)\n",
    "        #update the value in the pair[]\n",
    "        pt_value_set.add(temp_string)\n",
    "    \n",
    "    #main_to_sub map\n",
    "    products_to_all.update({pt_key:pt_value_set})\n",
    "    #product_to_num map\n",
    "    pt_index += 1\n",
    "    main_categories_map_to_num.update({pt_key:pt_index})\n",
    "\n",
    "main_categories_map_to_num.update({\"other\" : 8})\n",
    "main_categories_map_to_num.update({\"unknown\" : 0})\n",
    "#if key in [scandals, sneakers, heels, boots], or [boots, shirts, sweaters, jackets, coats]\n",
    "#print(\"Second: all main_categories\\n\", all_sub_main)\n",
    "\n",
    "all_sub = set()\n",
    "for key in st[0].keys():\n",
    "    product_name_3rd_list = st[0].get(key) # get list of []\n",
    "    for item_string in product_name_3rd_list: \n",
    "        #loop all item_string in order\n",
    "        temp = lemma_string(item_string)\n",
    "        temp_string = check_and_concat_punct(temp)\n",
    "        temp_list = lemma_string(key)\n",
    "        temp_string2 = check_and_concat_punct(temp_list)\n",
    "        all_sub.add(temp_string)\n",
    "        all_sub.add(temp_string2)\n",
    "#print(\"Third: all sub catrgories\\n\", all_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "input: the list of all sub_categories, the key of the main_categories\n",
    "function:put all sub_categories to the relative the main_categories set\n",
    "output: none\n",
    "'''\n",
    "def update_products_to_all(string_list : List, main_key: str)->None:\n",
    "    assert len(string_list) > 0\n",
    "    assert products_to_all.get(main_key) is not None\n",
    "    for item_string in string_list:\n",
    "        temp = lemma_string(item_string)\n",
    "        temp_string = check_and_concat_punct(temp) \n",
    "        products_to_all.get(main_key).add(temp_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add all sub categories to the main 8 categories.\n",
    "for key in sub_cat_all_keys:#loop all keys in sub_main_categories, \n",
    "    if key in sub_cat_tops_keys:#if the key belongs to tops\n",
    "        product_name_3rd_list = st[0].get(key)\n",
    "        update_products_to_all(product_name_3rd_list + sub_cat_tops_keys, 'tops')\n",
    "    elif key in sub_cat_shoes_keys:\n",
    "        product_name_3rd_list = st[0].get(key)\n",
    "        update_products_to_all(product_name_3rd_list + sub_cat_shoes_keys, 'shoes')\n",
    "    elif key in sub_cat_bottoms_keys:\n",
    "        product_name_3rd_list = st[0].get(key)\n",
    "        update_products_to_all(product_name_3rd_list + sub_cat_bottoms_keys, 'bottoms')\n",
    "    elif key in sub_cat_other_clothing_keys:\n",
    "        product_name_3rd_list = st[0].get(key)\n",
    "        update_products_to_all(product_name_3rd_list + sub_cat_other_clothing_keys, 'other_clothing')\n",
    "    elif key in sub_cat_acc_keys:\n",
    "        product_name_3rd_list = st[0].get(key)\n",
    "        update_products_to_all(product_name_3rd_list + sub_cat_acc_keys, 'accessories')\n",
    "    elif key in sub_cat_beauty_keys:\n",
    "        product_name_3rd_list = st[0].get(key)\n",
    "        update_products_to_all(product_name_3rd_list + sub_cat_beauty_keys, 'beauty') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in products_to_all.keys():\n",
    "    products_to_all.update({key: list(products_to_all.get(key))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Build the hashmap all products has mapped to the number of categories\n",
    "'''\n",
    "specific_products_map_to_num = {}\n",
    "for key in products_to_all.keys():\n",
    "    map_number_of_this_key = main_categories_map_to_num.get(key)\n",
    "    assert products_to_all.get(key) is not None\n",
    "    #include the main_categories to number;\n",
    "    specific_products_map_to_num.update({key: map_number_of_this_key})\n",
    "    for item in products_to_all.get(key):\n",
    "        specific_products_map_to_num.update({item: map_number_of_this_key})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deal with the second layer labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all specific labels should map to the one general second class label\n",
    "# for example , {\"swiming short\":\"shorts\"} in format: {\"label_3rd\" : \"label_2nd\"}\n",
    "label3_to_label2_map = {}\n",
    "f2 = open(\"json_files/labels_2nd.json\")\n",
    "labels_2nd = json.load(f2)\n",
    "main_cat = [k for k in labels_2nd.keys()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat in main_cat:\n",
    "    temp_dict = labels_2nd.get(cat)\n",
    "    for k in temp_dict.keys():\n",
    "        item_list = temp_dict.get(k)\n",
    "        \n",
    "        \n",
    "        for item_string in item_list:\n",
    "            temp = lemma_string(item_string)\n",
    "            temp_string = check_and_concat_punct(temp)\n",
    "            label3_to_label2_map.update({temp_string:k})\n",
    "            \n",
    "        temp_key = lemma_string(k)\n",
    "        key = check_and_concat_punct(temp_key)\n",
    "        label3_to_label2_map.update({key:k})\n",
    "            \n",
    "for key in [\"homeware\", \"others\"]:\n",
    "    item_list = products_to_all.get(key)\n",
    "    assert item_list != None\n",
    "    for item in item_list:\n",
    "        label3_to_label2_map.update({item: key})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pant trouser\n",
      "blazer suit\n",
      "other top\n"
     ]
    }
   ],
   "source": [
    "for k in label3_to_label2_map.keys():\n",
    "    if k not in specific_products_map_to_num.keys():\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save all maps to json files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save files\n",
    "with open(\"json_files/product_to_all.json\", \"w\") as f1:\n",
    "    json.dump(products_to_all, f1)\n",
    "#parsed = json.dumps(products_to_all, indent=4)\n",
    "with open(\"json_files/main_categories_to_num.json\",\"w\") as f2:\n",
    "    json.dump(main_categories_map_to_num,f2)\n",
    "\n",
    "with open(\"json_files/specific_product_map_to_num.json\", \"w\") as f3:\n",
    "    json.dump(specific_products_map_to_num, f3)\n",
    "    \n",
    "with open(\"json_files/label3_to_label2.json\", \"w\") as f4:\n",
    "    json.dump(label3_to_label2_map, f4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "08f33c96bfe48976e0772c3a4097c2fff4477ea59ec4556e2e8fa1251315c612"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
